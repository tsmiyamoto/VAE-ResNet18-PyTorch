{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "\n",
    "from natsort import natsorted\n",
    "from PIL import Image\n",
    "from skimage import io, transform\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.17.2-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
      "     |████████████████████████████████| 12.4 MB 4.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (8.3.2)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (2.5.1)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2020.9.3-py3-none-any.whl (148 kB)\n",
      "     |████████████████████████████████| 148 kB 93.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (2.13.3)\n",
      "Requirement already satisfied: numpy>=1.15.1 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (1.19.1)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (1.5.4)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (4.4 MB)\n",
      "     |████████████████████████████████| 4.4 MB 39.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (3.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (3.0.6)\n",
      "Collecting decorator<5,>=4.3\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.16.0)\n",
      "Installing collected packages: decorator, tifffile, PyWavelets, scikit-image\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.1.1\n",
      "    Uninstalling decorator-5.1.1:\n",
      "      Successfully uninstalled decorator-5.1.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ipython 7.16.3 requires jedi<=0.17.2,>=0.10, but you have jedi 0.18.0 which is incompatible.\u001b[0m\n",
      "Successfully installed PyWavelets-1.1.1 decorator-4.4.2 scikit-image-0.17.2 tifffile-2020.9.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = nn.Sequential(*list(model.children())[:-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               --                        --\n",
       "├─Conv2d: 1-1                            [1, 64, 128, 128]         9,408\n",
       "├─BatchNorm2d: 1-2                       [1, 64, 128, 128]         128\n",
       "├─ReLU: 1-3                              [1, 64, 128, 128]         --\n",
       "├─MaxPool2d: 1-4                         [1, 64, 64, 64]           --\n",
       "├─Sequential: 1-5                        [1, 64, 64, 64]           --\n",
       "│    └─BasicBlock: 2-1                   [1, 64, 64, 64]           --\n",
       "│    │    └─Conv2d: 3-1                  [1, 64, 64, 64]           36,864\n",
       "│    │    └─BatchNorm2d: 3-2             [1, 64, 64, 64]           128\n",
       "│    │    └─ReLU: 3-3                    [1, 64, 64, 64]           --\n",
       "│    │    └─Conv2d: 3-4                  [1, 64, 64, 64]           36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [1, 64, 64, 64]           128\n",
       "│    │    └─ReLU: 3-6                    [1, 64, 64, 64]           --\n",
       "│    └─BasicBlock: 2-2                   [1, 64, 64, 64]           --\n",
       "│    │    └─Conv2d: 3-7                  [1, 64, 64, 64]           36,864\n",
       "│    │    └─BatchNorm2d: 3-8             [1, 64, 64, 64]           128\n",
       "│    │    └─ReLU: 3-9                    [1, 64, 64, 64]           --\n",
       "│    │    └─Conv2d: 3-10                 [1, 64, 64, 64]           36,864\n",
       "│    │    └─BatchNorm2d: 3-11            [1, 64, 64, 64]           128\n",
       "│    │    └─ReLU: 3-12                   [1, 64, 64, 64]           --\n",
       "│    └─BasicBlock: 2-3                   [1, 64, 64, 64]           --\n",
       "│    │    └─Conv2d: 3-13                 [1, 64, 64, 64]           36,864\n",
       "│    │    └─BatchNorm2d: 3-14            [1, 64, 64, 64]           128\n",
       "│    │    └─ReLU: 3-15                   [1, 64, 64, 64]           --\n",
       "│    │    └─Conv2d: 3-16                 [1, 64, 64, 64]           36,864\n",
       "│    │    └─BatchNorm2d: 3-17            [1, 64, 64, 64]           128\n",
       "│    │    └─ReLU: 3-18                   [1, 64, 64, 64]           --\n",
       "├─Sequential: 1-6                        [1, 128, 32, 32]          --\n",
       "│    └─BasicBlock: 2-4                   [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-19                 [1, 128, 32, 32]          73,728\n",
       "│    │    └─BatchNorm2d: 3-20            [1, 128, 32, 32]          256\n",
       "│    │    └─ReLU: 3-21                   [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-22                 [1, 128, 32, 32]          147,456\n",
       "│    │    └─BatchNorm2d: 3-23            [1, 128, 32, 32]          256\n",
       "│    │    └─Sequential: 3-24             [1, 128, 32, 32]          --\n",
       "│    │    │    └─Conv2d: 4-1             [1, 128, 32, 32]          8,192\n",
       "│    │    │    └─BatchNorm2d: 4-2        [1, 128, 32, 32]          256\n",
       "│    │    └─ReLU: 3-25                   [1, 128, 32, 32]          --\n",
       "│    └─BasicBlock: 2-5                   [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-26                 [1, 128, 32, 32]          147,456\n",
       "│    │    └─BatchNorm2d: 3-27            [1, 128, 32, 32]          256\n",
       "│    │    └─ReLU: 3-28                   [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-29                 [1, 128, 32, 32]          147,456\n",
       "│    │    └─BatchNorm2d: 3-30            [1, 128, 32, 32]          256\n",
       "│    │    └─ReLU: 3-31                   [1, 128, 32, 32]          --\n",
       "│    └─BasicBlock: 2-6                   [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-32                 [1, 128, 32, 32]          147,456\n",
       "│    │    └─BatchNorm2d: 3-33            [1, 128, 32, 32]          256\n",
       "│    │    └─ReLU: 3-34                   [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-35                 [1, 128, 32, 32]          147,456\n",
       "│    │    └─BatchNorm2d: 3-36            [1, 128, 32, 32]          256\n",
       "│    │    └─ReLU: 3-37                   [1, 128, 32, 32]          --\n",
       "│    └─BasicBlock: 2-7                   [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-38                 [1, 128, 32, 32]          147,456\n",
       "│    │    └─BatchNorm2d: 3-39            [1, 128, 32, 32]          256\n",
       "│    │    └─ReLU: 3-40                   [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-41                 [1, 128, 32, 32]          147,456\n",
       "│    │    └─BatchNorm2d: 3-42            [1, 128, 32, 32]          256\n",
       "│    │    └─ReLU: 3-43                   [1, 128, 32, 32]          --\n",
       "├─Sequential: 1-7                        [1, 256, 16, 16]          --\n",
       "│    └─BasicBlock: 2-8                   [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-44                 [1, 256, 16, 16]          294,912\n",
       "│    │    └─BatchNorm2d: 3-45            [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU: 3-46                   [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-47                 [1, 256, 16, 16]          589,824\n",
       "│    │    └─BatchNorm2d: 3-48            [1, 256, 16, 16]          512\n",
       "│    │    └─Sequential: 3-49             [1, 256, 16, 16]          --\n",
       "│    │    │    └─Conv2d: 4-3             [1, 256, 16, 16]          32,768\n",
       "│    │    │    └─BatchNorm2d: 4-4        [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU: 3-50                   [1, 256, 16, 16]          --\n",
       "│    └─BasicBlock: 2-9                   [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-51                 [1, 256, 16, 16]          589,824\n",
       "│    │    └─BatchNorm2d: 3-52            [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU: 3-53                   [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-54                 [1, 256, 16, 16]          589,824\n",
       "│    │    └─BatchNorm2d: 3-55            [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU: 3-56                   [1, 256, 16, 16]          --\n",
       "│    └─BasicBlock: 2-10                  [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-57                 [1, 256, 16, 16]          589,824\n",
       "│    │    └─BatchNorm2d: 3-58            [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU: 3-59                   [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-60                 [1, 256, 16, 16]          589,824\n",
       "│    │    └─BatchNorm2d: 3-61            [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU: 3-62                   [1, 256, 16, 16]          --\n",
       "│    └─BasicBlock: 2-11                  [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-63                 [1, 256, 16, 16]          589,824\n",
       "│    │    └─BatchNorm2d: 3-64            [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU: 3-65                   [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-66                 [1, 256, 16, 16]          589,824\n",
       "│    │    └─BatchNorm2d: 3-67            [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU: 3-68                   [1, 256, 16, 16]          --\n",
       "│    └─BasicBlock: 2-12                  [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-69                 [1, 256, 16, 16]          589,824\n",
       "│    │    └─BatchNorm2d: 3-70            [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU: 3-71                   [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-72                 [1, 256, 16, 16]          589,824\n",
       "│    │    └─BatchNorm2d: 3-73            [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU: 3-74                   [1, 256, 16, 16]          --\n",
       "│    └─BasicBlock: 2-13                  [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-75                 [1, 256, 16, 16]          589,824\n",
       "│    │    └─BatchNorm2d: 3-76            [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU: 3-77                   [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-78                 [1, 256, 16, 16]          589,824\n",
       "│    │    └─BatchNorm2d: 3-79            [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU: 3-80                   [1, 256, 16, 16]          --\n",
       "├─Sequential: 1-8                        [1, 512, 8, 8]            --\n",
       "│    └─BasicBlock: 2-14                  [1, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-81                 [1, 512, 8, 8]            1,179,648\n",
       "│    │    └─BatchNorm2d: 3-82            [1, 512, 8, 8]            1,024\n",
       "│    │    └─ReLU: 3-83                   [1, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-84                 [1, 512, 8, 8]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-85            [1, 512, 8, 8]            1,024\n",
       "│    │    └─Sequential: 3-86             [1, 512, 8, 8]            --\n",
       "│    │    │    └─Conv2d: 4-5             [1, 512, 8, 8]            131,072\n",
       "│    │    │    └─BatchNorm2d: 4-6        [1, 512, 8, 8]            1,024\n",
       "│    │    └─ReLU: 3-87                   [1, 512, 8, 8]            --\n",
       "│    └─BasicBlock: 2-15                  [1, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-88                 [1, 512, 8, 8]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-89            [1, 512, 8, 8]            1,024\n",
       "│    │    └─ReLU: 3-90                   [1, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-91                 [1, 512, 8, 8]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-92            [1, 512, 8, 8]            1,024\n",
       "│    │    └─ReLU: 3-93                   [1, 512, 8, 8]            --\n",
       "│    └─BasicBlock: 2-16                  [1, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-94                 [1, 512, 8, 8]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-95            [1, 512, 8, 8]            1,024\n",
       "│    │    └─ReLU: 3-96                   [1, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-97                 [1, 512, 8, 8]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-98            [1, 512, 8, 8]            1,024\n",
       "│    │    └─ReLU: 3-99                   [1, 512, 8, 8]            --\n",
       "==========================================================================================\n",
       "Total params: 21,284,672\n",
       "Trainable params: 21,284,672\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 4.78\n",
       "==========================================================================================\n",
       "Input size (MB): 0.79\n",
       "Forward/backward pass size (MB): 78.12\n",
       "Params size (MB): 85.14\n",
       "Estimated Total Size (MB): 164.04\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(resnet, (1, 3, INPUT_SHAPE, INPUT_SHAPE), depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BasicBlockDec(nn.Module):\n",
    "\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        if shape == 512:\n",
    "            shape2 = 512\n",
    "        else:\n",
    "            shape2 = int(shape * 2)\n",
    "        \n",
    "        self.convtrans1 = nn.ConvTranspose2d(shape2, shape, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(shape)\n",
    "        self.convtrans2 = nn.ConvTranspose2d(shape, shape, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(shape)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = self.convtrans1(x)\n",
    "        out2 = torch.relu(self.bn1(out1))\n",
    "        out2 = self.convtrans2(out2)\n",
    "        out2 = torch.relu(self.bn2(out2))\n",
    "        final = torch.add(out1, out2)\n",
    "        \n",
    "        return final\n",
    "\n",
    "\n",
    "class ResNet18Dec(nn.Module):\n",
    "\n",
    "    def __init__(self, num_Blocks=[2,2,2,2], nc=3):\n",
    "        super().__init__()\n",
    "        self.layer1 = BasicBlockDec(512)\n",
    "        self.layer2 = BasicBlockDec(256)\n",
    "        self.layer3 = BasicBlockDec(128)\n",
    "        self.layer4 = BasicBlockDec(64)\n",
    "        self.conv1 = nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "#         self.conv1 = ResizeConv2d(64, nc, kernel_size=3, scale_factor=2)\n",
    "\n",
    "    def _make_layer(self, BasicBlockDec, shape):\n",
    "        return \n",
    "        strides = [stride] + [1]*(num_Blocks-1)\n",
    "        layers = []\n",
    "        for stride in reversed(strides):\n",
    "            layers += [BasicBlockDec(self.in_planes, stride)]\n",
    "        self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = torch.sigmoid(self.conv1(x))\n",
    "        return x\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = resnet\n",
    "        self.decoder = ResNet18Dec()\n",
    "        self.conv1 = nn.Conv2d(512, 512, kernel_size=1, stride=1)\n",
    "        self.conv2 = nn.Conv2d(512, 512, kernel_size=1, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         mean, logvar = self.encoder(x)\n",
    "        x = self.encoder(x)\n",
    "        x = torch.relu(self.conv1(x))\n",
    "#         x = torch.relu(self.conv2(x))\n",
    "#         z = self.reparameterize(mean, logvar)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "AutoEncoder                                   --                        --\n",
       "├─Sequential: 1-1                             [1, 512, 8, 8]            --\n",
       "│    └─Conv2d: 2-1                            [1, 64, 128, 128]         9,408\n",
       "│    └─BatchNorm2d: 2-2                       [1, 64, 128, 128]         128\n",
       "│    └─ReLU: 2-3                              [1, 64, 128, 128]         --\n",
       "│    └─MaxPool2d: 2-4                         [1, 64, 64, 64]           --\n",
       "│    └─Sequential: 2-5                        [1, 64, 64, 64]           --\n",
       "│    │    └─BasicBlock: 3-1                   [1, 64, 64, 64]           --\n",
       "│    │    │    └─Conv2d: 4-1                  [1, 64, 64, 64]           36,864\n",
       "│    │    │    └─BatchNorm2d: 4-2             [1, 64, 64, 64]           128\n",
       "│    │    │    └─ReLU: 4-3                    [1, 64, 64, 64]           --\n",
       "│    │    │    └─Conv2d: 4-4                  [1, 64, 64, 64]           36,864\n",
       "│    │    │    └─BatchNorm2d: 4-5             [1, 64, 64, 64]           128\n",
       "│    │    │    └─ReLU: 4-6                    [1, 64, 64, 64]           --\n",
       "│    │    └─BasicBlock: 3-2                   [1, 64, 64, 64]           --\n",
       "│    │    │    └─Conv2d: 4-7                  [1, 64, 64, 64]           36,864\n",
       "│    │    │    └─BatchNorm2d: 4-8             [1, 64, 64, 64]           128\n",
       "│    │    │    └─ReLU: 4-9                    [1, 64, 64, 64]           --\n",
       "│    │    │    └─Conv2d: 4-10                 [1, 64, 64, 64]           36,864\n",
       "│    │    │    └─BatchNorm2d: 4-11            [1, 64, 64, 64]           128\n",
       "│    │    │    └─ReLU: 4-12                   [1, 64, 64, 64]           --\n",
       "│    │    └─BasicBlock: 3-3                   [1, 64, 64, 64]           --\n",
       "│    │    │    └─Conv2d: 4-13                 [1, 64, 64, 64]           36,864\n",
       "│    │    │    └─BatchNorm2d: 4-14            [1, 64, 64, 64]           128\n",
       "│    │    │    └─ReLU: 4-15                   [1, 64, 64, 64]           --\n",
       "│    │    │    └─Conv2d: 4-16                 [1, 64, 64, 64]           36,864\n",
       "│    │    │    └─BatchNorm2d: 4-17            [1, 64, 64, 64]           128\n",
       "│    │    │    └─ReLU: 4-18                   [1, 64, 64, 64]           --\n",
       "│    └─Sequential: 2-6                        [1, 128, 32, 32]          --\n",
       "│    │    └─BasicBlock: 3-4                   [1, 128, 32, 32]          --\n",
       "│    │    │    └─Conv2d: 4-19                 [1, 128, 32, 32]          73,728\n",
       "│    │    │    └─BatchNorm2d: 4-20            [1, 128, 32, 32]          256\n",
       "│    │    │    └─ReLU: 4-21                   [1, 128, 32, 32]          --\n",
       "│    │    │    └─Conv2d: 4-22                 [1, 128, 32, 32]          147,456\n",
       "│    │    │    └─BatchNorm2d: 4-23            [1, 128, 32, 32]          256\n",
       "│    │    │    └─Sequential: 4-24             [1, 128, 32, 32]          --\n",
       "│    │    │    │    └─Conv2d: 5-1             [1, 128, 32, 32]          8,192\n",
       "│    │    │    │    └─BatchNorm2d: 5-2        [1, 128, 32, 32]          256\n",
       "│    │    │    └─ReLU: 4-25                   [1, 128, 32, 32]          --\n",
       "│    │    └─BasicBlock: 3-5                   [1, 128, 32, 32]          --\n",
       "│    │    │    └─Conv2d: 4-26                 [1, 128, 32, 32]          147,456\n",
       "│    │    │    └─BatchNorm2d: 4-27            [1, 128, 32, 32]          256\n",
       "│    │    │    └─ReLU: 4-28                   [1, 128, 32, 32]          --\n",
       "│    │    │    └─Conv2d: 4-29                 [1, 128, 32, 32]          147,456\n",
       "│    │    │    └─BatchNorm2d: 4-30            [1, 128, 32, 32]          256\n",
       "│    │    │    └─ReLU: 4-31                   [1, 128, 32, 32]          --\n",
       "│    │    └─BasicBlock: 3-6                   [1, 128, 32, 32]          --\n",
       "│    │    │    └─Conv2d: 4-32                 [1, 128, 32, 32]          147,456\n",
       "│    │    │    └─BatchNorm2d: 4-33            [1, 128, 32, 32]          256\n",
       "│    │    │    └─ReLU: 4-34                   [1, 128, 32, 32]          --\n",
       "│    │    │    └─Conv2d: 4-35                 [1, 128, 32, 32]          147,456\n",
       "│    │    │    └─BatchNorm2d: 4-36            [1, 128, 32, 32]          256\n",
       "│    │    │    └─ReLU: 4-37                   [1, 128, 32, 32]          --\n",
       "│    │    └─BasicBlock: 3-7                   [1, 128, 32, 32]          --\n",
       "│    │    │    └─Conv2d: 4-38                 [1, 128, 32, 32]          147,456\n",
       "│    │    │    └─BatchNorm2d: 4-39            [1, 128, 32, 32]          256\n",
       "│    │    │    └─ReLU: 4-40                   [1, 128, 32, 32]          --\n",
       "│    │    │    └─Conv2d: 4-41                 [1, 128, 32, 32]          147,456\n",
       "│    │    │    └─BatchNorm2d: 4-42            [1, 128, 32, 32]          256\n",
       "│    │    │    └─ReLU: 4-43                   [1, 128, 32, 32]          --\n",
       "│    └─Sequential: 2-7                        [1, 256, 16, 16]          --\n",
       "│    │    └─BasicBlock: 3-8                   [1, 256, 16, 16]          --\n",
       "│    │    │    └─Conv2d: 4-44                 [1, 256, 16, 16]          294,912\n",
       "│    │    │    └─BatchNorm2d: 4-45            [1, 256, 16, 16]          512\n",
       "│    │    │    └─ReLU: 4-46                   [1, 256, 16, 16]          --\n",
       "│    │    │    └─Conv2d: 4-47                 [1, 256, 16, 16]          589,824\n",
       "│    │    │    └─BatchNorm2d: 4-48            [1, 256, 16, 16]          512\n",
       "│    │    │    └─Sequential: 4-49             [1, 256, 16, 16]          --\n",
       "│    │    │    │    └─Conv2d: 5-3             [1, 256, 16, 16]          32,768\n",
       "│    │    │    │    └─BatchNorm2d: 5-4        [1, 256, 16, 16]          512\n",
       "│    │    │    └─ReLU: 4-50                   [1, 256, 16, 16]          --\n",
       "│    │    └─BasicBlock: 3-9                   [1, 256, 16, 16]          --\n",
       "│    │    │    └─Conv2d: 4-51                 [1, 256, 16, 16]          589,824\n",
       "│    │    │    └─BatchNorm2d: 4-52            [1, 256, 16, 16]          512\n",
       "│    │    │    └─ReLU: 4-53                   [1, 256, 16, 16]          --\n",
       "│    │    │    └─Conv2d: 4-54                 [1, 256, 16, 16]          589,824\n",
       "│    │    │    └─BatchNorm2d: 4-55            [1, 256, 16, 16]          512\n",
       "│    │    │    └─ReLU: 4-56                   [1, 256, 16, 16]          --\n",
       "│    │    └─BasicBlock: 3-10                  [1, 256, 16, 16]          --\n",
       "│    │    │    └─Conv2d: 4-57                 [1, 256, 16, 16]          589,824\n",
       "│    │    │    └─BatchNorm2d: 4-58            [1, 256, 16, 16]          512\n",
       "│    │    │    └─ReLU: 4-59                   [1, 256, 16, 16]          --\n",
       "│    │    │    └─Conv2d: 4-60                 [1, 256, 16, 16]          589,824\n",
       "│    │    │    └─BatchNorm2d: 4-61            [1, 256, 16, 16]          512\n",
       "│    │    │    └─ReLU: 4-62                   [1, 256, 16, 16]          --\n",
       "│    │    └─BasicBlock: 3-11                  [1, 256, 16, 16]          --\n",
       "│    │    │    └─Conv2d: 4-63                 [1, 256, 16, 16]          589,824\n",
       "│    │    │    └─BatchNorm2d: 4-64            [1, 256, 16, 16]          512\n",
       "│    │    │    └─ReLU: 4-65                   [1, 256, 16, 16]          --\n",
       "│    │    │    └─Conv2d: 4-66                 [1, 256, 16, 16]          589,824\n",
       "│    │    │    └─BatchNorm2d: 4-67            [1, 256, 16, 16]          512\n",
       "│    │    │    └─ReLU: 4-68                   [1, 256, 16, 16]          --\n",
       "│    │    └─BasicBlock: 3-12                  [1, 256, 16, 16]          --\n",
       "│    │    │    └─Conv2d: 4-69                 [1, 256, 16, 16]          589,824\n",
       "│    │    │    └─BatchNorm2d: 4-70            [1, 256, 16, 16]          512\n",
       "│    │    │    └─ReLU: 4-71                   [1, 256, 16, 16]          --\n",
       "│    │    │    └─Conv2d: 4-72                 [1, 256, 16, 16]          589,824\n",
       "│    │    │    └─BatchNorm2d: 4-73            [1, 256, 16, 16]          512\n",
       "│    │    │    └─ReLU: 4-74                   [1, 256, 16, 16]          --\n",
       "│    │    └─BasicBlock: 3-13                  [1, 256, 16, 16]          --\n",
       "│    │    │    └─Conv2d: 4-75                 [1, 256, 16, 16]          589,824\n",
       "│    │    │    └─BatchNorm2d: 4-76            [1, 256, 16, 16]          512\n",
       "│    │    │    └─ReLU: 4-77                   [1, 256, 16, 16]          --\n",
       "│    │    │    └─Conv2d: 4-78                 [1, 256, 16, 16]          589,824\n",
       "│    │    │    └─BatchNorm2d: 4-79            [1, 256, 16, 16]          512\n",
       "│    │    │    └─ReLU: 4-80                   [1, 256, 16, 16]          --\n",
       "│    └─Sequential: 2-8                        [1, 512, 8, 8]            --\n",
       "│    │    └─BasicBlock: 3-14                  [1, 512, 8, 8]            --\n",
       "│    │    │    └─Conv2d: 4-81                 [1, 512, 8, 8]            1,179,648\n",
       "│    │    │    └─BatchNorm2d: 4-82            [1, 512, 8, 8]            1,024\n",
       "│    │    │    └─ReLU: 4-83                   [1, 512, 8, 8]            --\n",
       "│    │    │    └─Conv2d: 4-84                 [1, 512, 8, 8]            2,359,296\n",
       "│    │    │    └─BatchNorm2d: 4-85            [1, 512, 8, 8]            1,024\n",
       "│    │    │    └─Sequential: 4-86             [1, 512, 8, 8]            --\n",
       "│    │    │    │    └─Conv2d: 5-5             [1, 512, 8, 8]            131,072\n",
       "│    │    │    │    └─BatchNorm2d: 5-6        [1, 512, 8, 8]            1,024\n",
       "│    │    │    └─ReLU: 4-87                   [1, 512, 8, 8]            --\n",
       "│    │    └─BasicBlock: 3-15                  [1, 512, 8, 8]            --\n",
       "│    │    │    └─Conv2d: 4-88                 [1, 512, 8, 8]            2,359,296\n",
       "│    │    │    └─BatchNorm2d: 4-89            [1, 512, 8, 8]            1,024\n",
       "│    │    │    └─ReLU: 4-90                   [1, 512, 8, 8]            --\n",
       "│    │    │    └─Conv2d: 4-91                 [1, 512, 8, 8]            2,359,296\n",
       "│    │    │    └─BatchNorm2d: 4-92            [1, 512, 8, 8]            1,024\n",
       "│    │    │    └─ReLU: 4-93                   [1, 512, 8, 8]            --\n",
       "│    │    └─BasicBlock: 3-16                  [1, 512, 8, 8]            --\n",
       "│    │    │    └─Conv2d: 4-94                 [1, 512, 8, 8]            2,359,296\n",
       "│    │    │    └─BatchNorm2d: 4-95            [1, 512, 8, 8]            1,024\n",
       "│    │    │    └─ReLU: 4-96                   [1, 512, 8, 8]            --\n",
       "│    │    │    └─Conv2d: 4-97                 [1, 512, 8, 8]            2,359,296\n",
       "│    │    │    └─BatchNorm2d: 4-98            [1, 512, 8, 8]            1,024\n",
       "│    │    │    └─ReLU: 4-99                   [1, 512, 8, 8]            --\n",
       "├─Conv2d: 1-2                                 [1, 512, 8, 8]            262,656\n",
       "├─ResNet18Dec: 1-3                            [1, 3, 256, 256]          --\n",
       "│    └─BasicBlockDec: 2-9                     [1, 512, 16, 16]          --\n",
       "│    │    └─ConvTranspose2d: 3-17             [1, 512, 16, 16]          4,194,816\n",
       "│    │    └─BatchNorm2d: 3-18                 [1, 512, 16, 16]          1,024\n",
       "│    │    └─ConvTranspose2d: 3-19             [1, 512, 16, 16]          2,359,808\n",
       "│    │    └─BatchNorm2d: 3-20                 [1, 512, 16, 16]          1,024\n",
       "│    └─BasicBlockDec: 2-10                    [1, 256, 32, 32]          --\n",
       "│    │    └─ConvTranspose2d: 3-21             [1, 256, 32, 32]          2,097,408\n",
       "│    │    └─BatchNorm2d: 3-22                 [1, 256, 32, 32]          512\n",
       "│    │    └─ConvTranspose2d: 3-23             [1, 256, 32, 32]          590,080\n",
       "│    │    └─BatchNorm2d: 3-24                 [1, 256, 32, 32]          512\n",
       "│    └─BasicBlockDec: 2-11                    [1, 128, 64, 64]          --\n",
       "│    │    └─ConvTranspose2d: 3-25             [1, 128, 64, 64]          524,416\n",
       "│    │    └─BatchNorm2d: 3-26                 [1, 128, 64, 64]          256\n",
       "│    │    └─ConvTranspose2d: 3-27             [1, 128, 64, 64]          147,584\n",
       "│    │    └─BatchNorm2d: 3-28                 [1, 128, 64, 64]          256\n",
       "│    └─BasicBlockDec: 2-12                    [1, 64, 128, 128]         --\n",
       "│    │    └─ConvTranspose2d: 3-29             [1, 64, 128, 128]         131,136\n",
       "│    │    └─BatchNorm2d: 3-30                 [1, 64, 128, 128]         128\n",
       "│    │    └─ConvTranspose2d: 3-31             [1, 64, 128, 128]         36,928\n",
       "│    │    └─BatchNorm2d: 3-32                 [1, 64, 128, 128]         128\n",
       "│    └─ConvTranspose2d: 2-13                  [1, 3, 256, 256]          3,075\n",
       "===============================================================================================\n",
       "Total params: 31,636,419\n",
       "Trainable params: 31,636,419\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 14.94\n",
       "===============================================================================================\n",
       "Input size (MB): 0.79\n",
       "Forward/backward pass size (MB): 142.87\n",
       "Params size (MB): 126.55\n",
       "Estimated Total Size (MB): 270.20\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae = AutoEncoder().cuda()\n",
    "summary(ae, (1, 3, INPUT_SHAPE, INPUT_SHAPE), depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 75\n",
    "LR = 0.0004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadFromFolder(Dataset):\n",
    "    def __init__(self, main_dir, transform):\n",
    "        self.main_dir = main_dir\n",
    "        self.transform = transform\n",
    "        all_imgs = natsorted(os.listdir(main_dir))\n",
    "        self.all_imgs_name = natsorted(all_imgs)\n",
    "        self.imgs_loc = [os.path.join(self.main_dir, i) for i in self.all_imgs_name]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_imgs_name)\n",
    "    \n",
    "    def load_image(self, path):\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "        tensor_image = self.transform(image)\n",
    "        return tensor_image\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # 後ほどsliceで画像を複数枚取得したいのでsliceでも取れるようにする\n",
    "        if type(idx) == slice:\n",
    "            paths = self.imgs_loc[idx]\n",
    "            tensor_image = [self.load_image(path) for path in paths]\n",
    "            tensor_image = torch.cat(tensor_image).reshape(len(tensor_image), *tensor_image[0].shape)\n",
    "        elif type(idx) == int:\n",
    "            path = self.imgs_loc[idx]\n",
    "            tensor_image = self.load_image(path)\n",
    "        return tensor_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_dict = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),  # IMAGE_SIZEにreshape\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    ),\n",
    "    \"test\": transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),  # IMAGE_SIZEにreshape\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_root = './cap_dataset/white_omote_crop/train/good/'  # train dataの保存してあるディレクトリ\n",
    "train_root = './cap_dataset/white_omote_crop_shadow/train/good/'  # train dataの保存してあるディレクトリ\n",
    "\n",
    "train_dataset = LoadFromFolder(train_root, transform=transform_dict[\"train\"])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder().cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,dataloader,otpimizer,criterion,num_epochs):\n",
    "\n",
    "    for epoch in range(1,num_epochs+1):\n",
    "                \n",
    "        total_loss = 0\n",
    "        corrects = 0\n",
    "        total = 0\n",
    "\n",
    "        with tqdm(total=len(dataloader),unit=\"batch\") as pbar:\n",
    "            pbar.set_description(f\"Epoch[{epoch}/{num_epochs}]\")\n",
    "            for imgs in dataloader: \n",
    "                imgs = Variable(imgs).cuda()\n",
    "                output = model(imgs)\n",
    "                loss = criterion(output, imgs)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total += imgs.size(0)\n",
    "\n",
    "\n",
    "                total_loss += loss.data / total\n",
    "                pbar.set_postfix({\"loss\":total_loss.item()})\n",
    "                pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[1/100]: 100%|██████████| 6/6 [00:11<00:00,  1.87s/batch, loss=0.00387]\n",
      "Epoch[2/100]: 100%|██████████| 6/6 [00:09<00:00,  1.57s/batch, loss=0.000859]\n",
      "Epoch[3/100]: 100%|██████████| 6/6 [00:09<00:00,  1.57s/batch, loss=0.000355]\n",
      "Epoch[4/100]: 100%|██████████| 6/6 [00:09<00:00,  1.58s/batch, loss=0.000207]\n",
      "Epoch[5/100]: 100%|██████████| 6/6 [00:09<00:00,  1.57s/batch, loss=0.000156]\n",
      "Epoch[6/100]: 100%|██████████| 6/6 [00:09<00:00,  1.57s/batch, loss=0.000212]\n",
      "Epoch[7/100]: 100%|██████████| 6/6 [00:09<00:00,  1.59s/batch, loss=0.000171]\n",
      "Epoch[8/100]: 100%|██████████| 6/6 [00:09<00:00,  1.58s/batch, loss=0.000136]\n",
      "Epoch[9/100]: 100%|██████████| 6/6 [00:09<00:00,  1.58s/batch, loss=0.000122]\n",
      "Epoch[10/100]: 100%|██████████| 6/6 [00:09<00:00,  1.59s/batch, loss=0.000111]\n",
      "Epoch[11/100]: 100%|██████████| 6/6 [00:09<00:00,  1.58s/batch, loss=0.000108]\n",
      "Epoch[12/100]: 100%|██████████| 6/6 [00:09<00:00,  1.59s/batch, loss=8.94e-5]\n",
      "Epoch[13/100]: 100%|██████████| 6/6 [00:09<00:00,  1.61s/batch, loss=8.02e-5]\n",
      "Epoch[14/100]: 100%|██████████| 6/6 [00:09<00:00,  1.60s/batch, loss=7.5e-5] \n",
      "Epoch[15/100]: 100%|██████████| 6/6 [00:09<00:00,  1.60s/batch, loss=6.91e-5]\n",
      "Epoch[16/100]: 100%|██████████| 6/6 [00:09<00:00,  1.61s/batch, loss=6.92e-5]\n",
      "Epoch[17/100]: 100%|██████████| 6/6 [00:09<00:00,  1.60s/batch, loss=7.43e-5]\n",
      "Epoch[18/100]: 100%|██████████| 6/6 [00:09<00:00,  1.61s/batch, loss=7.64e-5]\n",
      "Epoch[19/100]: 100%|██████████| 6/6 [00:09<00:00,  1.61s/batch, loss=6.38e-5]\n",
      "Epoch[20/100]: 100%|██████████| 6/6 [00:09<00:00,  1.60s/batch, loss=6.57e-5]\n",
      "Epoch[21/100]: 100%|██████████| 6/6 [00:09<00:00,  1.61s/batch, loss=7.15e-5]\n",
      "Epoch[22/100]: 100%|██████████| 6/6 [00:09<00:00,  1.61s/batch, loss=5.88e-5]\n",
      "Epoch[23/100]: 100%|██████████| 6/6 [00:09<00:00,  1.62s/batch, loss=5.02e-5]\n",
      "Epoch[24/100]: 100%|██████████| 6/6 [00:09<00:00,  1.62s/batch, loss=4.71e-5]\n",
      "Epoch[25/100]: 100%|██████████| 6/6 [00:09<00:00,  1.62s/batch, loss=4.54e-5]\n",
      "Epoch[26/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=4.46e-5]\n",
      "Epoch[27/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=4.25e-5]\n",
      "Epoch[28/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=4.1e-5] \n",
      "Epoch[29/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=3.76e-5]\n",
      "Epoch[30/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=3.49e-5]\n",
      "Epoch[31/100]: 100%|██████████| 6/6 [00:09<00:00,  1.61s/batch, loss=3.34e-5]\n",
      "Epoch[32/100]: 100%|██████████| 6/6 [00:09<00:00,  1.62s/batch, loss=3.2e-5] \n",
      "Epoch[33/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=3.14e-5]\n",
      "Epoch[34/100]: 100%|██████████| 6/6 [00:09<00:00,  1.62s/batch, loss=2.92e-5]\n",
      "Epoch[35/100]: 100%|██████████| 6/6 [00:09<00:00,  1.62s/batch, loss=2.77e-5]\n",
      "Epoch[36/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=2.79e-5]\n",
      "Epoch[37/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=2.63e-5]\n",
      "Epoch[38/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=2.45e-5]\n",
      "Epoch[39/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=2.32e-5]\n",
      "Epoch[40/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=2.32e-5]\n",
      "Epoch[41/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=2.28e-5]\n",
      "Epoch[42/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=2.29e-5]\n",
      "Epoch[43/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=2.42e-5]\n",
      "Epoch[44/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=2.27e-5]\n",
      "Epoch[45/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=2.16e-5]\n",
      "Epoch[46/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=2.28e-5]\n",
      "Epoch[47/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=2.02e-5]\n",
      "Epoch[48/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=2.31e-5]\n",
      "Epoch[49/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=2.53e-5]\n",
      "Epoch[50/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=2.54e-5]\n",
      "Epoch[51/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=2.1e-5] \n",
      "Epoch[52/100]: 100%|██████████| 6/6 [00:09<00:00,  1.65s/batch, loss=1.99e-5]\n",
      "Epoch[53/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=1.95e-5]\n",
      "Epoch[54/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=2.04e-5]\n",
      "Epoch[55/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=2.26e-5]\n",
      "Epoch[56/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=2.2e-5] \n",
      "Epoch[57/100]: 100%|██████████| 6/6 [00:09<00:00,  1.65s/batch, loss=1.99e-5]\n",
      "Epoch[58/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=1.94e-5]\n",
      "Epoch[59/100]: 100%|██████████| 6/6 [00:09<00:00,  1.65s/batch, loss=1.87e-5]\n",
      "Epoch[60/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=1.85e-5]\n",
      "Epoch[61/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=1.73e-5]\n",
      "Epoch[62/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=1.57e-5]\n",
      "Epoch[63/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=1.61e-5]\n",
      "Epoch[64/100]: 100%|██████████| 6/6 [00:09<00:00,  1.65s/batch, loss=1.58e-5]\n",
      "Epoch[65/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=1.72e-5]\n",
      "Epoch[66/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=1.62e-5]\n",
      "Epoch[67/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=1.51e-5]\n",
      "Epoch[68/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=1.58e-5]\n",
      "Epoch[69/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=1.5e-5] \n",
      "Epoch[70/100]: 100%|██████████| 6/6 [00:09<00:00,  1.65s/batch, loss=1.38e-5]\n",
      "Epoch[71/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=1.45e-5]\n",
      "Epoch[72/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=4.83e-5]\n",
      "Epoch[73/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=0.000163]\n",
      "Epoch[74/100]: 100%|██████████| 6/6 [00:09<00:00,  1.62s/batch, loss=0.000162]\n",
      "Epoch[75/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=0.000104]\n",
      "Epoch[76/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=0.000265]\n",
      "Epoch[77/100]: 100%|██████████| 6/6 [00:09<00:00,  1.62s/batch, loss=0.000184]\n",
      "Epoch[78/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=8.96e-5]\n",
      "Epoch[79/100]: 100%|██████████| 6/6 [00:09<00:00,  1.62s/batch, loss=7.36e-5]\n",
      "Epoch[80/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=5.2e-5] \n",
      "Epoch[81/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=3.95e-5]\n",
      "Epoch[82/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=0.000159]\n",
      "Epoch[83/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=0.000105]\n",
      "Epoch[84/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=7.42e-5]\n",
      "Epoch[85/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=5.86e-5]\n",
      "Epoch[86/100]: 100%|██████████| 6/6 [00:09<00:00,  1.62s/batch, loss=4.78e-5]\n",
      "Epoch[87/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=5.43e-5]\n",
      "Epoch[88/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=4.97e-5]\n",
      "Epoch[89/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=3.37e-5]\n",
      "Epoch[90/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=3.22e-5]\n",
      "Epoch[91/100]: 100%|██████████| 6/6 [00:09<00:00,  1.62s/batch, loss=2.64e-5]\n",
      "Epoch[92/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=2.99e-5]\n",
      "Epoch[93/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=2.79e-5]\n",
      "Epoch[94/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=2.51e-5]\n",
      "Epoch[95/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=1.73e-5]\n",
      "Epoch[96/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=2.17e-5]\n",
      "Epoch[97/100]: 100%|██████████| 6/6 [00:09<00:00,  1.63s/batch, loss=2.05e-5]\n",
      "Epoch[98/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=1.77e-5]\n",
      "Epoch[99/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=2.09e-5]\n",
      "Epoch[100/100]: 100%|██████████| 6/6 [00:09<00:00,  1.64s/batch, loss=1.88e-5]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "train(model, train_loader, optimizer, criterion, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.datetime.today()\n",
    "today = today.strftime('%m%d%H%M')\n",
    "pkl_path = \"resnet34AE_{}_{}epoch.pkl\".format(today, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), pkl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.8 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/pytorch-1.8-gpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
