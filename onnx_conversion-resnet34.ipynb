{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
    "resnet = nn.Sequential(*list(model.children())[:-2])\n",
    "\n",
    "\n",
    "class BasicBlockDec(nn.Module):\n",
    "\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        if shape == 512:\n",
    "            shape2 = 512\n",
    "        else:\n",
    "            shape2 = int(shape * 2)\n",
    "        \n",
    "        self.convtrans1 = nn.ConvTranspose2d(shape2, shape, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(shape)\n",
    "        self.convtrans2 = nn.ConvTranspose2d(shape, shape, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(shape)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = self.convtrans1(x)\n",
    "        out2 = torch.relu(self.bn1(out1))\n",
    "        out2 = self.convtrans2(out2)\n",
    "        out2 = torch.relu(self.bn2(out2))\n",
    "        final = torch.add(out1, out2)\n",
    "        \n",
    "        return final\n",
    "\n",
    "\n",
    "class ResNet18Dec(nn.Module):\n",
    "\n",
    "    def __init__(self, num_Blocks=[2,2,2,2], nc=3):\n",
    "        super().__init__()\n",
    "        self.layer1 = BasicBlockDec(512)\n",
    "        self.layer2 = BasicBlockDec(256)\n",
    "        self.layer3 = BasicBlockDec(128)\n",
    "        self.layer4 = BasicBlockDec(64)\n",
    "        self.conv1 = nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "#         self.conv1 = ResizeConv2d(64, nc, kernel_size=3, scale_factor=2)\n",
    "\n",
    "    def _make_layer(self, BasicBlockDec, shape):\n",
    "        return \n",
    "        strides = [stride] + [1]*(num_Blocks-1)\n",
    "        layers = []\n",
    "        for stride in reversed(strides):\n",
    "            layers += [BasicBlockDec(self.in_planes, stride)]\n",
    "        self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = torch.sigmoid(self.conv1(x))\n",
    "        return x\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = resnet\n",
    "        self.decoder = ResNet18Dec()\n",
    "        self.conv1 = nn.Conv2d(512, 512, kernel_size=1, stride=1)\n",
    "        self.conv2 = nn.Conv2d(512, 512, kernel_size=1, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         mean, logvar = self.encoder(x)\n",
    "        x = self.encoder(x)\n",
    "        x = torch.relu(self.conv1(x))\n",
    "#         x = torch.relu(self.conv2(x))\n",
    "#         z = self.reparameterize(mean, logvar)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): ResNet18Dec(\n",
       "    (layer1): BasicBlockDec(\n",
       "      (convtrans1): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (convtrans2): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (layer2): BasicBlockDec(\n",
       "      (convtrans1): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (convtrans2): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (layer3): BasicBlockDec(\n",
       "      (convtrans1): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (convtrans2): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (layer4): BasicBlockDec(\n",
       "      (convtrans1): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (convtrans2): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  )\n",
       "  (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = \"resnet34AE_04211523_100epoch\"\n",
    "pkl_path = prefix + \".pkl\"\n",
    "model = AutoEncoder().cuda()\n",
    "model.load_state_dict(torch.load(pkl_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input : Float(1, 3, 256, 256, strides=[196608, 65536, 256, 1], requires_grad=0, device=cuda:0),\n",
      "      %decoder.layer1.convtrans1.weight : Float(512, 512, 4, 4, strides=[8192, 16, 4, 1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer1.convtrans1.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer1.bn1.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer1.bn1.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer1.bn1.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %decoder.layer1.bn1.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %decoder.layer1.convtrans2.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer1.convtrans2.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer1.bn2.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer1.bn2.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer1.bn2.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %decoder.layer1.bn2.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %decoder.layer2.convtrans1.weight : Float(512, 256, 4, 4, strides=[4096, 16, 4, 1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer2.convtrans1.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer2.bn1.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer2.bn1.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer2.bn1.running_mean : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %decoder.layer2.bn1.running_var : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %decoder.layer2.convtrans2.weight : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer2.convtrans2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer2.bn2.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer2.bn2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer2.bn2.running_mean : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %decoder.layer2.bn2.running_var : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %decoder.layer3.convtrans1.weight : Float(256, 128, 4, 4, strides=[2048, 16, 4, 1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer3.convtrans1.bias : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer3.bn1.weight : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer3.bn1.bias : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer3.bn1.running_mean : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %decoder.layer3.bn1.running_var : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %decoder.layer3.convtrans2.weight : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer3.convtrans2.bias : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer3.bn2.weight : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer3.bn2.bias : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer3.bn2.running_mean : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %decoder.layer3.bn2.running_var : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %decoder.layer4.convtrans1.weight : Float(128, 64, 4, 4, strides=[1024, 16, 4, 1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer4.convtrans1.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer4.bn1.weight : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer4.bn1.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer4.bn1.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %decoder.layer4.bn1.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %decoder.layer4.convtrans2.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer4.convtrans2.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer4.bn2.weight : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer4.bn2.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.layer4.bn2.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %decoder.layer4.bn2.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %decoder.conv1.weight : Float(64, 3, 4, 4, strides=[48, 16, 4, 1], requires_grad=1, device=cuda:0),\n",
      "      %decoder.conv1.bias : Float(3, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %conv1.weight : Float(512, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %conv1.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %434 : Float(64, 3, 7, 7, strides=[147, 49, 7, 1], requires_grad=0, device=cuda:0),\n",
      "      %435 : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %437 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %438 : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %440 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %441 : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %443 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %444 : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %446 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %447 : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %449 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %450 : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %452 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %453 : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %455 : Float(128, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %456 : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %458 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %459 : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %461 : Float(128, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %462 : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %464 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %465 : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %467 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %468 : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %470 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %471 : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %473 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %474 : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %476 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %477 : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %479 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %480 : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %482 : Float(256, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %483 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %485 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %486 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %488 : Float(256, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %489 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %491 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %492 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %494 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %495 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %497 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %498 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %500 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %501 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %503 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %504 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %506 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %507 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %509 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %510 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %512 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %513 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %515 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %516 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %518 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %519 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %521 : Float(512, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %522 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %524 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %525 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %527 : Float(512, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %528 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %530 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %531 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %533 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %534 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %536 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %537 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %539 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %540 : Float(512, strides=[1], requires_grad=0, device=cuda:0)):\n",
      "  %433 : Float(1, 64, 128, 128, strides=[1048576, 16384, 128, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[3, 3, 3, 3], strides=[2, 2]](%input, %434, %435)\n",
      "  %281 : Float(1, 64, 128, 128, strides=[1048576, 16384, 128, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%433) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1204:0\n",
      "  %282 : Float(1, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cuda:0) = onnx::MaxPool[kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%281)\n",
      "  %436 : Float(1, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%282, %437, %438)\n",
      "  %285 : Float(1, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%436) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1204:0\n",
      "  %439 : Float(1, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%285, %440, %441)\n",
      "  %288 : Float(1, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cuda:0) = onnx::Add(%439, %282) # /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:80:0\n",
      "  %289 : Float(1, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%288)\n",
      "  %442 : Float(1, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%289, %443, %444)\n",
      "  %292 : Float(1, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%442) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1204:0\n",
      "  %445 : Float(1, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%292, %446, %447)\n",
      "  %295 : Float(1, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cuda:0) = onnx::Add(%445, %289) # /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:80:0\n",
      "  %296 : Float(1, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%295)\n",
      "  %448 : Float(1, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%296, %449, %450)\n",
      "  %299 : Float(1, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%448) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1204:0\n",
      "  %451 : Float(1, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%299, %452, %453)\n",
      "  %302 : Float(1, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cuda:0) = onnx::Add(%451, %296) # /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:80:0\n",
      "  %303 : Float(1, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%302) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1204:0\n",
      "  %454 : Float(1, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%303, %455, %456)\n",
      "  %306 : Float(1, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%454) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1204:0\n",
      "  %457 : Float(1, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%306, %458, %459)\n",
      "  %460 : Float(1, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%303, %461, %462)\n",
      "  %311 : Float(1, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::Add(%457, %460) # /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:80:0\n",
      "  %312 : Float(1, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%311)\n",
      "  %463 : Float(1, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%312, %464, %465)\n",
      "  %315 : Float(1, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%463) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1204:0\n",
      "  %466 : Float(1, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%315, %467, %468)\n",
      "  %318 : Float(1, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::Add(%466, %312) # /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:80:0\n",
      "  %319 : Float(1, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%318)\n",
      "  %469 : Float(1, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%319, %470, %471)\n",
      "  %322 : Float(1, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%469) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1204:0\n",
      "  %472 : Float(1, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%322, %473, %474)\n",
      "  %325 : Float(1, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::Add(%472, %319) # /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:80:0\n",
      "  %326 : Float(1, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%325)\n",
      "  %475 : Float(1, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%326, %476, %477)\n",
      "  %329 : Float(1, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%475) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1204:0\n",
      "  %478 : Float(1, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%329, %479, %480)\n",
      "  %332 : Float(1, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::Add(%478, %326) # /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:80:0\n",
      "  %333 : Float(1, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%332) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1204:0\n",
      "  %481 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%333, %482, %483)\n",
      "  %336 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%481) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1204:0\n",
      "  %484 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%336, %485, %486)\n",
      "  %487 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%333, %488, %489)\n",
      "  %341 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Add(%484, %487) # /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:80:0\n",
      "  %342 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%341)\n",
      "  %490 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%342, %491, %492)\n",
      "  %345 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%490) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1204:0\n",
      "  %493 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%345, %494, %495)\n",
      "  %348 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Add(%493, %342) # /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:80:0\n",
      "  %349 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%348)\n",
      "  %496 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%349, %497, %498)\n",
      "  %352 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%496) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1204:0\n",
      "  %499 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%352, %500, %501)\n",
      "  %355 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Add(%499, %349) # /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:80:0\n",
      "  %356 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%355)\n",
      "  %502 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%356, %503, %504)\n",
      "  %359 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%502) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1204:0\n",
      "  %505 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%359, %506, %507)\n",
      "  %362 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Add(%505, %356) # /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:80:0\n",
      "  %363 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%362)\n",
      "  %508 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%363, %509, %510)\n",
      "  %366 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%508) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1204:0\n",
      "  %511 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%366, %512, %513)\n",
      "  %369 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Add(%511, %363) # /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:80:0\n",
      "  %370 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%369)\n",
      "  %514 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%370, %515, %516)\n",
      "  %373 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%514) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1204:0\n",
      "  %517 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%373, %518, %519)\n",
      "  %376 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Add(%517, %370) # /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:80:0\n",
      "  %377 : Float(1, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%376) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1204:0\n",
      "  %520 : Float(1, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%377, %521, %522)\n",
      "  %380 : Float(1, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%520) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1204:0\n",
      "  %523 : Float(1, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%380, %524, %525)\n",
      "  %526 : Float(1, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%377, %527, %528)\n",
      "  %385 : Float(1, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cuda:0) = onnx::Add(%523, %526) # /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:80:0\n",
      "  %386 : Float(1, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%385)\n",
      "  %529 : Float(1, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%386, %530, %531)\n",
      "  %389 : Float(1, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%529) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1204:0\n",
      "  %532 : Float(1, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%389, %533, %534)\n",
      "  %392 : Float(1, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cuda:0) = onnx::Add(%532, %386) # /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:80:0\n",
      "  %393 : Float(1, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%392)\n",
      "  %535 : Float(1, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%393, %536, %537)\n",
      "  %396 : Float(1, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%535) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1204:0\n",
      "  %538 : Float(1, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%396, %539, %540)\n",
      "  %399 : Float(1, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cuda:0) = onnx::Add(%538, %393) # /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:80:0\n",
      "  %400 : Float(1, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%399) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1204:0\n",
      "  %401 : Float(1, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%400, %conv1.weight, %conv1.bias) # /opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py:396:0\n",
      "  %402 : Float(1, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%401) # <ipython-input-10-bccea62d88cc>:72:0\n",
      "  %403 : Float(1, 512, 16, 16, strides=[131072, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[4, 4], pads=[1, 1, 1, 1], strides=[2, 2]](%402, %decoder.layer1.convtrans1.weight, %decoder.layer1.convtrans1.bias) # /opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py:842:0\n",
      "  %404 : Float(1, 512, 16, 16, strides=[131072, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%403, %decoder.layer1.bn1.weight, %decoder.layer1.bn1.bias, %decoder.layer1.bn1.running_mean, %decoder.layer1.bn1.running_var) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2150:0\n",
      "  %405 : Float(1, 512, 16, 16, strides=[131072, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%404) # <ipython-input-10-bccea62d88cc>:21:0\n",
      "  %406 : Float(1, 512, 16, 16, strides=[131072, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%405, %decoder.layer1.convtrans2.weight, %decoder.layer1.convtrans2.bias) # /opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py:842:0\n",
      "  %407 : Float(1, 512, 16, 16, strides=[131072, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%406, %decoder.layer1.bn2.weight, %decoder.layer1.bn2.bias, %decoder.layer1.bn2.running_mean, %decoder.layer1.bn2.running_var) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2150:0\n",
      "  %408 : Float(1, 512, 16, 16, strides=[131072, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%407) # <ipython-input-10-bccea62d88cc>:23:0\n",
      "  %409 : Float(1, 512, 16, 16, strides=[131072, 256, 16, 1], requires_grad=1, device=cuda:0) = onnx::Add(%403, %408) # <ipython-input-10-bccea62d88cc>:24:0\n",
      "  %410 : Float(1, 256, 32, 32, strides=[262144, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[4, 4], pads=[1, 1, 1, 1], strides=[2, 2]](%409, %decoder.layer2.convtrans1.weight, %decoder.layer2.convtrans1.bias) # /opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py:842:0\n",
      "  %411 : Float(1, 256, 32, 32, strides=[262144, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%410, %decoder.layer2.bn1.weight, %decoder.layer2.bn1.bias, %decoder.layer2.bn1.running_mean, %decoder.layer2.bn1.running_var) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2150:0\n",
      "  %412 : Float(1, 256, 32, 32, strides=[262144, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%411) # <ipython-input-10-bccea62d88cc>:21:0\n",
      "  %413 : Float(1, 256, 32, 32, strides=[262144, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%412, %decoder.layer2.convtrans2.weight, %decoder.layer2.convtrans2.bias) # /opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py:842:0\n",
      "  %414 : Float(1, 256, 32, 32, strides=[262144, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%413, %decoder.layer2.bn2.weight, %decoder.layer2.bn2.bias, %decoder.layer2.bn2.running_mean, %decoder.layer2.bn2.running_var) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2150:0\n",
      "  %415 : Float(1, 256, 32, 32, strides=[262144, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%414) # <ipython-input-10-bccea62d88cc>:23:0\n",
      "  %416 : Float(1, 256, 32, 32, strides=[262144, 1024, 32, 1], requires_grad=1, device=cuda:0) = onnx::Add(%410, %415) # <ipython-input-10-bccea62d88cc>:24:0\n",
      "  %417 : Float(1, 128, 64, 64, strides=[524288, 4096, 64, 1], requires_grad=1, device=cuda:0) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[4, 4], pads=[1, 1, 1, 1], strides=[2, 2]](%416, %decoder.layer3.convtrans1.weight, %decoder.layer3.convtrans1.bias) # /opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py:842:0\n",
      "  %418 : Float(1, 128, 64, 64, strides=[524288, 4096, 64, 1], requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%417, %decoder.layer3.bn1.weight, %decoder.layer3.bn1.bias, %decoder.layer3.bn1.running_mean, %decoder.layer3.bn1.running_var) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2150:0\n",
      "  %419 : Float(1, 128, 64, 64, strides=[524288, 4096, 64, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%418) # <ipython-input-10-bccea62d88cc>:21:0\n",
      "  %420 : Float(1, 128, 64, 64, strides=[524288, 4096, 64, 1], requires_grad=1, device=cuda:0) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%419, %decoder.layer3.convtrans2.weight, %decoder.layer3.convtrans2.bias) # /opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py:842:0\n",
      "  %421 : Float(1, 128, 64, 64, strides=[524288, 4096, 64, 1], requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%420, %decoder.layer3.bn2.weight, %decoder.layer3.bn2.bias, %decoder.layer3.bn2.running_mean, %decoder.layer3.bn2.running_var) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2150:0\n",
      "  %422 : Float(1, 128, 64, 64, strides=[524288, 4096, 64, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%421) # <ipython-input-10-bccea62d88cc>:23:0\n",
      "  %423 : Float(1, 128, 64, 64, strides=[524288, 4096, 64, 1], requires_grad=1, device=cuda:0) = onnx::Add(%417, %422) # <ipython-input-10-bccea62d88cc>:24:0\n",
      "  %424 : Float(1, 64, 128, 128, strides=[1048576, 16384, 128, 1], requires_grad=1, device=cuda:0) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[4, 4], pads=[1, 1, 1, 1], strides=[2, 2]](%423, %decoder.layer4.convtrans1.weight, %decoder.layer4.convtrans1.bias) # /opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py:842:0\n",
      "  %425 : Float(1, 64, 128, 128, strides=[1048576, 16384, 128, 1], requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%424, %decoder.layer4.bn1.weight, %decoder.layer4.bn1.bias, %decoder.layer4.bn1.running_mean, %decoder.layer4.bn1.running_var) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2150:0\n",
      "  %426 : Float(1, 64, 128, 128, strides=[1048576, 16384, 128, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%425) # <ipython-input-10-bccea62d88cc>:21:0\n",
      "  %427 : Float(1, 64, 128, 128, strides=[1048576, 16384, 128, 1], requires_grad=1, device=cuda:0) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%426, %decoder.layer4.convtrans2.weight, %decoder.layer4.convtrans2.bias) # /opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py:842:0\n",
      "  %428 : Float(1, 64, 128, 128, strides=[1048576, 16384, 128, 1], requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%427, %decoder.layer4.bn2.weight, %decoder.layer4.bn2.bias, %decoder.layer4.bn2.running_mean, %decoder.layer4.bn2.running_var) # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2150:0\n",
      "  %429 : Float(1, 64, 128, 128, strides=[1048576, 16384, 128, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%428) # <ipython-input-10-bccea62d88cc>:23:0\n",
      "  %430 : Float(1, 64, 128, 128, strides=[1048576, 16384, 128, 1], requires_grad=1, device=cuda:0) = onnx::Add(%424, %429) # <ipython-input-10-bccea62d88cc>:24:0\n",
      "  %431 : Float(1, 3, 256, 256, strides=[196608, 65536, 256, 1], requires_grad=1, device=cuda:0) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[4, 4], pads=[1, 1, 1, 1], strides=[2, 2]](%430, %decoder.conv1.weight, %decoder.conv1.bias) # /opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py:842:0\n",
      "  %output : Float(1, 3, 256, 256, strides=[196608, 65536, 256, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%431) # <ipython-input-10-bccea62d88cc>:57:0\n",
      "  return (%output)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.randn(1, 3, 256, 256, device=\"cuda\")\n",
    "\n",
    "torch.onnx.export(model, dummy_input, f\"{prefix}.onnx\", verbose=True, input_names=[\"input\"], output_names=[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.8 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/pytorch-1.8-gpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
